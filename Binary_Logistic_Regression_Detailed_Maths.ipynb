{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary_Logistic_Regression_Detailed_Maths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$.Different Between Generative and Discriminative Classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$.How Naive Bayes Classifier Different from Binary Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$.From Where This Logistic Function or Sigmoid Function Come. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$4$. Learning In Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$5$.Loss Function Of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$6$.Optimization Of Loss Function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Different Between Generative and Discriminative Classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's take an example we are trying to distinguish dog image and cat image. A generative model would have the goal of understanding what dogs look like and what cats look like. You might literally ask such a model to 'generate',i.e.draw a dog. Given a test image , the system then asks whether it's the cat model or the dog model that better fit the image, and chooses that as its label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is an example of Generative Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In generative model we can't directly computing ${P(y|x)}$ that is your ${Posterior Probability}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we compute  ${Likelihood Probability}$ and ${Prior Probability}$ through which we can calculate the ${Posterior Probability}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A discriminantive model, by contrast, is only trying to learn to distinguish the classes. So may be all the dogs in the training data are wearing collars and the cats are not. If that on feature nearly separates the classes, the model is satisfied, if you ask such a model what it knows about cats all it can say it that they do not wear collars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is an example of Discriminiative Classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this discriminative model we directly computing the ${P(y|x)}$ that is your ${Posterior Probability}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps it will learn to assing a high weight to features that directly improve its ability to ${discriminiate}$ between possible classes, even if could not generate an example of one of the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 .How Naive Bayes Classifier Different from Binary Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\cdot}$${Naive Bayes classifier}$  is a generative model in which for computing the  ${P(y|x)}$ is ${Posterior Porbability}$ \n",
    "first we compte the ${P(x|y)}$ is ${Likelihood Probability}$ and ${Prior Probability}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${Naive Bayes Classifier}$ is Non-parametric learining algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ${Naive Bayes Classifier}$ we Assume IID(Independet and Identically Distributed) between features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\cdot}$${Logistic Regression}$ is a discriminative classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${Logistic Rgression}$ is Parametric Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.From Where This Logistic Function or Sigmoid Function Come."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have Binary class dataset in which random variables of the given features are continuous in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features of the given data you can represent this by $X$=$[{x}_1,{x}_2,{x}_3,{x}_4.............{x}_N]$ where N is the size of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and our labels are represent as $y$=$[{0},{1}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, from ${Bayes Rule}$ we know that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(A|B) = \\frac{P(B|A)\\cdot{P(A)}}{P(B)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here some notation define. $A$ is $y$ ${\\in}$ $[0,1]$ and B is $X$=$[{x}_1,{x}_2,{x}_3...............{x}_N]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(A|B) = \\frac{P(B|A)\\cdot{P(A)}}{P(B|A)\\cdot{P(A)} + P(B|A^{\\complement})\\cdot{P(A^{\\complement})}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(y=1|X) = \\frac{P(X|y=1)\\cdot{P(y=1)}}{P(X|y=1)\\cdot{P(y=1) + P(X|y=0)\\cdot{P(y=0)}}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so ${P(y=1)}$ and ${P(y=0)}$ is ${0.5}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(y=1|X) = \\frac{P(X|y=1)}{P(X|y=1) + P(X|y=0)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and ${P(X|y=1) + P(X|y=0)}$ is Normalized Probability same for ${P(y=1|X)}$ and ${P(y=0|X)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our final result is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "equation no. ${1}$\n",
    "\\begin{equation}\n",
    "P(y=1|X)\\propto{P(X|y=1)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and similarly for\n",
    "equation no. ${2}$\n",
    "\\begin{equation}\n",
    "P(y=0|X)\\propto{P(X|y=0)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are dividing the equation ${1}$ by ${2}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{P(y=1|X={x}_i)}{P(y=0|X={x}_i)} = \\frac{P(X={x}_i|y=1)}{P(X={x}_i|y=0)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we know that our random variables of the given features are continuous in nature and we can say this random varibales come from some probability distribution, and that we assume that that probability distribution is gaussian in nature. So we can used ${Likelihood Probability}$ as ${PDF}$ of gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "PDF= \\frac{1}{\\sqrt{2{\\pi}{\\sigma}}}e^{-}\\frac{(x-\\mu)^2}{2{\\sigma}^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{P(y=1|X={x}_i)}{P(y=0|X={x}_i)} = \\frac{\\frac{1}{\\sqrt{2{\\pi}{\\sigma}1}}e^{-}\\frac{({x}_i-{\\mu}_1)^2}{2{\\sigma}_1^2}}{\\frac{1}{\\sqrt{2{\\pi}{\\sigma}_0}}e^{-}\\frac{({x}_i-{\\mu}_0)^2}{2{\\sigma}_0^2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we assume that our ${\\sigma}_0^2$ and ${\\sigma}_1^2$ (variances are equal) ${\\sigma}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{P(y=1|X={x}_i)}{P(y=0|X={x}_i)} = \\frac{\\frac{1}{\\sqrt{2{\\pi}{\\sigma}}}e^{-}\\frac{({x}_i-{\\mu}_1)^2}{2{\\sigma}^2}}{\\frac{1}{\\sqrt{2{\\pi}{\\sigma}}}e^{-}\\frac{({x}_i-{\\mu}_0)^2}{2{\\sigma}^2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after solving some step.\n",
    "\\begin{equation}\n",
    "\\frac{P(y=1|X={x}_i)}{P(y=0|X={x}_i)} = \\frac{e^{-}\\frac{({x}_i-{\\mu}_1)^2}{2{\\sigma}^2}}     {e^{-}\\frac{({x}_i-{\\mu}_0)^2}{2{\\sigma}^2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{P(y=1|X={x}_i)}{P(y=0|X={x}_i)} =  e^{\\frac{({x}_i - {\\mu}_0)^2}{2{\\sigma}^2} -\\frac{({x}_i - {\\mu}_1)^2}{2{\\sigma}^2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{P(y=1|X={x}_i)}{P(y=0|X={x}_i)} = e^{\\frac{({x}_i - {\\mu}_0 + {x}_i - {\\mu}_1)\\cdot{({x}_i - {\\mu}_0 - {x}_i + {\\mu}_1)}}{2{\\sigma}^2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{P(y=1|X={x}_i)}{P(y=0|X={x}_i)} = e^{\\frac{(2{x}_i -({\\mu}_1 + {\\mu}_0))\\cdot{({\\mu}_1 - {\\mu}_0)}}{2{\\sigma}^2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{P(y=1|X={x}_i)}{P(y=0|X={x}_i)} = e^{\\frac{({x}_i\\cdot{({\\mu}_1 - {\\mu}_0)})}{\\sigma^2} - \\frac{({\\mu}_i^2 - {\\mu}_0^2)}{2{\\sigma}^2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define some notation for this parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\theta}_1 = \\frac{({\\mu}_1 - {\\mu}_0)}{\\sigma^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and\n",
    "\\begin{equation}\n",
    "{\\theta}_0 = \\frac{-({\\mu}_1^2 - {\\mu}_0^2)}{2{\\sigma}^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our updated equation is.\n",
    "\\begin{equation}\n",
    "\\frac{P(y=1|X={x}_i)}{P(y=0|X={x}_i)} = e^{({x}_i\\cdot{\\theta}_1 + {\\theta}_0)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{P(y=0|X={x}_i)}{P(y=1|X={x}_i)} = e^{{-}({x}_i\\cdot{\\theta}_1 + {\\theta}_0)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{1 - P(y=1|X={x}_i)}{P(y=1|X={x}_i)} = e^{-({x}_i\\cdot{\\theta}_1 + {\\theta}_0)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{1}{P(y=1|X={x}_i)} - 1 = e^{-({x}_i\\cdot{\\theta}_1 + {\\theta}_0)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{1}{P(y=1|X={x}_i)} = 1 + e^{-({x}_i\\cdot{\\theta}_1 + {\\theta}_0)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(y=1|X={x}_i) = \\frac{1}{1 + e^{-({x}_i\\cdot{\\theta}_1 + {\\theta}_0)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and\n",
    "\\begin{equation}\n",
    "P(y=0|X={x}_i) = (1 - \\frac{1}{1 + e^{-({x}_i\\cdot{\\theta}_1 + {\\theta}_0)}})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${Posterior Probability}$ of ${class = 1\n",
    "}$ is $\\frac{1}{1 + e^{-({x}_i\\cdot{\\theta}_1 + {\\theta}_0)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${Posterior Probability}$ of ${class = 0\n",
    "}$ is $ 1 - \\frac{1}{1 + e^{-({x}_i\\cdot{\\theta}_1 + {\\theta}_0)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "Sigmoidfunction = \\frac{1}{1 + e^{-({x}_i\\cdot{\\theta}_1 + {\\theta}_0)}} = Logistic function\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid has a number of advantages, it take a real-valued number and maps it into the range$[0,1]$ , which is just what we want for a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is nearly linear around $0$ but has sharp slop toward the ends, it tends to squash outlier values toward $0$ or $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an alogithm that given an instance ${x}$ computes the ${P(y=1|X=x)}$. How do we make a decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a test instance ${x}$ , we say yes if probability ${P(y=1|X=x)}$ is more than ${0.5}$ and no otherwish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call ${0.5}$ the ${Decision Boundary}:$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Learning In Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the parameters of the model, the weight ${w}$ and bias ${b}$, learned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is an instance of supervised classification in which we know the correct label ${y}$(either 0 or 1) for each observation ${x}$. What the system produces is $\\hat{y}$, the system's estimate of the true ${y}$. We want to learn parameters(meaning ${w}$ and ${b}$) that make $\\hat{y}$ for each training observation as closed to possible to the true ${y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This requires $2$ components that we foreshadowed in the introduction in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ${first}$ is a matric for how closed the current label $\\hat{y}$ is to the true label ${y}$. Rather than measure similarity, we usually talk about the opposit of this. the ${distance}$ between the system output and the true output, and we call this distance the ${loss}$ function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ${second}$ thing we need is an optimization algorithm for iteratively updating the weight so as to minimize the loss function. The standard algorithm is called ${gradient descent}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 .Loss Function Of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cross-entropy loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need a loss function that expresses , for an observation ${x}$, how close the classifier output $\\hat{y}$ = $\\frac{1}{1 + e^{-({x}\\cdot{\\theta}_1 + {\\theta}_0)}}$ is to the correct ouput (${y}$ ,which is $0$ or $1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L(\\hat{y},y) = {How-much-\\hat{y}-differs-from-the-true-{y}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this via a loss function that prefers the correct class labels of the training examples to be more like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called conditional maximum likelihood estimation we choose the parameters ${\\theta}_1$ ,${\\theta}_1$ that maximize the log probability of the true ${y}$ labels in the training data given the observation ${x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the resulting loss function is the negative log likelihood loss, generally called the ${cross-entropy-loss}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets' derive this loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applied to a single observation. we would like to learn weight that maximize the probability of the correct label${P(y|x)}$. Since there are only two discrete outcomes (1 or 0), this is a ${Bernoulli- distrubution}$ and we can express the probability ${P(y|x)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That our classifier produces for one observation as the following(keeping in mind that if${y}$= 1 simplifiers to $\\hat{y}$, if ${y}$ = 0 simplifier to ${1 - \\hat{y}}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(y|x) = \\hat{y}^{(y)}\\cdot(1- \\hat{y})^{(1-y)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you Likelihood function.\n",
    "\\begin{equation}\n",
    "P(y|x) = L(\\hat{y},y) = \\hat{y}^{(y)}\\cdot{(1- \\hat{y})}^{(1 - y)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for N-training-examples.\n",
    "\\begin{equation}\n",
    "P(y|x) = L(\\hat{y},y) = \\prod_{i=1}^N\\hat{y}^{({y}_i)}\\cdot{(1-\\hat{y})^{(1- {y}_i)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now at this time we are taking only on example.\n",
    "\n",
    "\\begin{equation}\n",
    "P(y|x) = L(\\hat{y},y) = \\hat{y}^{(y)}\\cdot{(1- \\hat{y})}^{(1 - y)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take the log of both sides. This will turn out to be handy mathmematically, whatever values maximize a probability will also maximize the log of the probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\n",
    "L(\\hat{y},y) = \\log[\\hat{y}^{(y)}\\cdot{(1- \\hat{y})^{(1- y)}}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L(\\hat{y},y) = y\\cdot{\\log}\\hat{y} + (1- y)\\cdot{\\log}{(1 - \\hat{y})}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a log likelihood that should  be maximized. in order to turn this minimized the negative log likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L(\\hat{y},y) = -[y\\cdot{\\log}\\hat{y} + (1- y)\\cdot{\\log}{(1 - \\hat{y})}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we know that.\n",
    "\\begin{equation}\n",
    "\\hat{y} = \\frac{1}{1 + e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our Likelihood function.\n",
    "\\begin{equation}\n",
    "{L}_{CE}({\\theta}_0,{\\theta}_1) = -[y\\cdot{\\log}{\\frac{1}{1 + e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)}}} + (1 - y)\\cdot{\\log}({1 - \\frac{1}{1 + e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)}}})]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this result is called. ${Cross-Entropy-Loss}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does minimzing this negative log probability do what we want? A pefect classifier  would assign probability 1 to correct outcome(${y}$=0 or ${y}$=1) and probability 0 to the incorrect outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That mean the higher $\\hat{y}$ (to closer it is to $1$). the better the classifier the lower $\\hat{y}$(the closer it is to $0$),the worse the classifier. The negative log of this probability is a convenient loss metric since it goes from $0$ (negative log of $1$, no loss) to infinity (negative log of $0$ , infinit loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loss function also ensures that as the proabability of the correct answer is maximized,the probability of the incorrect answer is minimized , since the two sum to one , any increase in the probability of the correct answer is coming at the expense of the incorrect answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is called the cross-entropy loss. because is also the formula for the cross-entropy between the true probability distribution ${y}$ and our estimated distribution $\\hat{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 .Optimization Of Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our goal with gradient descent is to find the optimal weights. and minimize the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\max_{{\\theta}_0,{\\theta}_1} \\log{L}_{CE}({\\theta}_0,{\\theta}_1)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\min_{{\\theta}_0,{\\theta}_1} -\\log{L}_{CE}({\\theta}_0,{\\theta}_1)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is a method that finds a minimum of a function by figuring out in which direction the function's slop is rising the most steeply, and moving in the opposite direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logistic regression this loss function is conveniently ${convex}$. A convex function has just one minimum. there are no local minima to get stuck in so gradient descent starting from any point in guaranteed to find the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${Gradient-Descent-Algorithm}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\theta}_0^{final} = {\\theta}_0^{initial} - {\\alpha}\\frac{\\partial}{\\partial {\\theta}_0}L({\\theta}_0,{\\theta}_1)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\theta}_1^{final} = {\\theta}_1^{initial} - {\\alpha}\\frac{\\partial}{\\partial {\\theta}_1}L({\\theta}_0,{\\theta}_1)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${gradient}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the gardient descent algorithm answers this question by finding the ${gradient}$ of the loss function at the current point and moving in the opposite direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of a  function  of many variables is a vector pointing in the direction of the greatest increase in a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let first compute gradient of.\n",
    "\\begin{equation}\n",
    "\\frac{\\partial}{\\partial {\\theta}_1}L({\\theta}_0,{\\theta}_1) = ?\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L({\\theta}_0,{\\theta}_1) = L(\\hat{y},{y})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's start.\n",
    "\\begin{equation}\n",
    "\\frac{\\partial}{\\partial {\\theta}_1}L({\\theta}_0,{\\theta}_1) = \\frac{\\partial L({\\theta}_0,{\\theta}_1)}{\\partial \\hat{y}}\\cdot{\\frac{\\partial \\hat{y}}{\\partial {\\theta}_1}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we compute.\n",
    "\\begin{equation}\n",
    "\\frac{\\partial L({\\theta}_0,{\\theta}_1)}{\\partial \\hat{y}} = \\frac{\\partial}{\\partial \\hat{y}}-[y\\cdot{\\log{\\hat{y}}} + (1 - y)\\cdot{\\log{1 - \\hat{y}}}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial L({\\theta}_0,{\\theta}_1)}{\\partial \\hat{y}} = [\\frac{(1- y)}{1 - \\hat{y}} - \\frac{y}{\\hat{y}}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial L({\\theta}_0,{\\theta}_1)}{\\partial \\hat{y}} = \\frac{\\hat{y} - y}{\\hat{y}\\cdot{(1- \\hat{y})}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial \\hat{y}}{\\partial {\\theta}_1} = \\frac{\\partial}{\\partial {\\theta}_1}{\\frac{1}{1 + e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)}}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial \\hat{y}}{\\partial {\\theta}_1} = {\\frac{-1}{(1 + e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)})^2}}\\frac{\\partial}{\\partial {\\theta}_1}{e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial \\hat{y}}{\\partial {\\theta}_1} = {\\frac{-1}{(1 + e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)})^2}}\\cdot{{e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)}}}\\frac{\\partial}{\\partial {\\theta}_1}(-(x\\cdot{\\theta}_1 + {\\theta}_0))\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial \\hat{y}}{\\partial {\\theta}_1} = {\\frac{-1}{(1 + e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)})^2}}\\cdot{{e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)}}}\\cdot{(-x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial \\hat{y}}{\\partial {\\theta}_1} = {\\frac{-1}{(1 + e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)})}}\\cdot{\\frac{e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)}}{(1 + e^{-(x\\cdot{\\theta}_1 + {\\theta}_0)})}}\\cdot{(-x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after solving this.\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\hat{y}}{\\partial {\\theta}_1} = \\hat{y}\\cdot{(1 - \\hat{y})}\\cdot{x}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the final result of\n",
    "\\begin{equation}\n",
    "\\frac{\\partial}{\\partial {\\theta}_1}L({\\theta}_0,{\\theta}_1) = (\\frac{\\hat{y} - y}{\\hat{y}\\cdot{(1 - \\hat{y})}})\\cdot{(\\hat{y}\\cdot{(1 - \\hat{y})}\\cdot{x})}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after solving this.\n",
    "\\begin{equation}\n",
    "\\frac{\\partial}{\\partial {\\theta}_1}L({\\theta}_0,{\\theta}_1) = (\\hat{y} - y)\\cdot{x}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarly when you follow the same steps for ${\\theta}_0$. the result is.\n",
    "\\begin{equation}\n",
    "\\frac{\\partial}{\\partial {\\theta}_0}L({\\theta}_0,{\\theta}_1) = (\\hat{y} - y)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our finaly gradient descent algorithm look's like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\theta}_0^{final} = {\\theta}_0^{initial} - {\\alpha}\\cdot{(\\hat{y} - y)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\theta}_1^{final} = {\\theta}_1^{initial} - {\\alpha}\\cdot{(\\hat{y} - y)\\cdot{x}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\alpha}$ is called Learning rate. A higher learning rate means that we should move ${\\theta}$ more on each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
